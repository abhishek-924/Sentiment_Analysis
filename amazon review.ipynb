{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('C:\\ghost drive\\study\\ds\\sentiment analysis\\Amazon_Unlocked_Mobile.csv')\n",
    "\n",
    "#drops empty rows\n",
    "df.dropna(inplace=True) \n",
    "\n",
    "\n",
    "#gives rows where rating is 3\n",
    "df=df[df['Rating']!=3] \n",
    "\n",
    "#create a column where '1' is for rating >3 and '0' is for rating<3\n",
    "df['positive or negative']=np.where(df['Rating']>3,1,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \n",
    "                                                    df['positive or negative'], \n",
    "                                                    random_state=0)\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the bag of words approach\n",
    "it do not focuses on structure, but it counts the no. of times the word is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CountVectorizer- It allows us to use the bag-of-words approach by converting a collection of text documents into a matrix of token counts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<231207x53216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6117776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#it tokenizes\n",
    "#converts everything to lowercase\n",
    "#builds a vocabulary\n",
    "#creates n number of features \n",
    "count=CountVectorizer().fit(X_train)\n",
    "#accessing vocabulary\n",
    "count.get_feature_names()[::200]\n",
    "#transforming to matrix representation of bag of words\n",
    "transform_matrix=count.transform(X_train)\n",
    "transform_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use logistic regression for high dimentional data and for the outcome of only +ve or -ve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(transform_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "predictions=model.predict(count.transform(X_test))\n",
    "predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942940012143\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17951"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train_vectorized=vect.transform(X_train)\n",
    "#LogisticRegression().fit(X_train_vectorized,y_train)\n",
    "#predictions=LogisticRegression().predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n grams= 1. not an issue, phone is working',2. 'an issue, phone is not working\n",
    "#both will come -ve by any other method\n",
    "#n grams solves this situation\n",
    "#it collects 2,3 words ek saath like bigrams or trigrams and the analysis if it is +ve or -ve\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,3)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  92.6610066675 %\n"
     ]
    }
   ],
   "source": [
    "#ROC (Receiver Operating Characteristic) Curve tells us about how good the \n",
    "#model can distinguish between two things (e.g If a patient has a disease or no). \n",
    "\n",
    "#for roc_auc score> 90\n",
    "#ROC curve is large.\n",
    "\n",
    "print('AUC: ', ((roc_auc_score(y_test, predictions))*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Coefs: \n",
      "['not bad' 'excelent' 'excelente' 'excellent' 'perfect' 'no problems'\n",
      " 'exelente' 'awesome' 'no issues' 'great']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "#sorting bigrams in -ve and +ve way and separating them\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'it is not working fine'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#it is an example of regression,classification and reinforcement learning \n",
    "#it is not an example of clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
